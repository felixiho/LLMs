{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPkTuM+tNBkWvBwJv6Cra79",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "799acf87553e4e878217139fed6136b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e4f0ccf22d85492dace13d7b85c2d029",
              "IPY_MODEL_9474ddb0034146a29e4a69b8b8c02dab",
              "IPY_MODEL_11d2eedb77944c908a8f2879b2d3637b"
            ],
            "layout": "IPY_MODEL_952b1feccb2c41c590ba80a2d943c325"
          }
        },
        "e4f0ccf22d85492dace13d7b85c2d029": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28872541b14e41e8858be64a14724414",
            "placeholder": "​",
            "style": "IPY_MODEL_fa089ae791674e2192f3630a01c8a208",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "9474ddb0034146a29e4a69b8b8c02dab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74266304df9d4ccda7a7bb35ced5eab2",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_225d08b9e58746af8cba448c62055e7d",
            "value": 2
          }
        },
        "11d2eedb77944c908a8f2879b2d3637b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f871b019e361494eace08c342baffd60",
            "placeholder": "​",
            "style": "IPY_MODEL_f7b8367824bf420fb8a41eb1d1c7a285",
            "value": " 2/2 [00:00&lt;00:00,  3.00it/s]"
          }
        },
        "952b1feccb2c41c590ba80a2d943c325": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28872541b14e41e8858be64a14724414": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa089ae791674e2192f3630a01c8a208": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "74266304df9d4ccda7a7bb35ced5eab2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "225d08b9e58746af8cba448c62055e7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f871b019e361494eace08c342baffd60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7b8367824bf420fb8a41eb1d1c7a285": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/felixiho/LLMs/blob/main/Transaction_Compliance_Monitoring_Agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transactions Compliance Monitoring With Document Injestion"
      ],
      "metadata": {
        "id": "EIgyBp6-_9Kq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --quiet datasets pymongo langchain-mongodb langgraph-checkpoint-mongodb langchain-core langchain-huggingface langgraph pypdf python-docx unstructured pydantic voyageai transformers torch accelerator"
      ],
      "metadata": {
        "collapsed": true,
        "id": "uF728juUAMs9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "def set_env_variables(variable):\n",
        "  value = getpass.getpass(f\"Enter the value for {variable}:\")\n",
        "  if len(value):\n",
        "    os.environ[variable] = value\n",
        "\n",
        "# os.environ[\"MONGO_DB_URI\"]\n",
        "# set_env_variables(\"TEST_VARIABLE\")\n",
        "\n",
        "\n",
        "set_env_variables(\"MONGO_DB_URI\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GP_06xfOAQtI",
        "outputId": "31f04069-c188-4096-8331-e546c7b75303"
      },
      "execution_count": 39,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the value for MONGO_DB_URI:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mongo DB Setup"
      ],
      "metadata": {
        "id": "tbm2REQSDIzx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pymongo.mongo_client import MongoClient\n",
        "from pymongo.server_api import ServerApi\n",
        "\n",
        "db_uri = os.environ.get(\"MONGO_DB_URI\")\n",
        "if not db_uri:\n",
        "  raise ValueError(\"MONGO_DB_URI environment variable is not set\")\n",
        "\n",
        "client = MongoClient(\n",
        "    db_uri,\n",
        "    server_api=ServerApi('1'),\n",
        "    appname=\"transaction_monitoring_with_document_injestion\"\n",
        ")\n",
        "\n",
        "DB_NAME = \"transaction_compliance\"\n",
        "TRANSACTIONS = \"transactions\"\n",
        "REGULATIONS = \"regulations\"\n",
        "CHECKPOINTS = \"checkpoints\"\n",
        "CHECKPOINTS_WRITES = \"checkpoints_writes\"\n",
        "\n",
        "try:\n",
        "    client.admin.command('ping')\n",
        "    print(\"Pinged your deployment. You successfully connected to MongoDB!\")\n",
        "except Exception as e:\n",
        "    print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAhxtFTkDLFY",
        "outputId": "9efbb252-d113-48c2-ec98-57d941bf7454"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vd:27017: [Errno -2] Name or service not known (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 682353038fc97133b9f004ed, topology_type: Unknown, servers: [<ServerDescription ('vd', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('vd:27017: [Errno -2] Name or service not known (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create MongoDB Collections for:\n",
        "\n",
        "\n",
        "1.   Transactions\n",
        "2.   Regulations\n",
        "3.   Checkpoints\n",
        "4.   Checkpoints Writes\n",
        "\n"
      ],
      "metadata": {
        "id": "v2HG0tWaIvRT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "db = client[DB_NAME]\n",
        "transaction_collection = db[TRANSACTIONS]\n",
        "regulations_collection = db[REGULATIONS]\n",
        "checkpoints_collection = db[CHECKPOINTS]\n",
        "checkpoints_writes_collection = db[CHECKPOINTS_WRITES]\n",
        "\n",
        "def create_mongodb_collections():\n",
        "  existing_collections = db.list_collection_names()\n",
        "\n",
        "  # Transactions collections\n",
        "  if TRANSACTIONS not in existing_collections:\n",
        "    db.create_collection(\n",
        "        TRANSACTIONS,\n",
        "        validator={\n",
        "            \"$jsonSchema\": {\n",
        "                \"bsonType\": \"object\",\n",
        "                \"required\": [\n",
        "                    'transaction_id',\n",
        "                    'amount',\n",
        "                    'currency',\n",
        "                    'sender',\n",
        "                    'receiver',\n",
        "                    'transaction_date'\n",
        "                ],\n",
        "                \"properties\": {\n",
        "                    \"transaction_id\": {\"bsonType\": \"string\"},\n",
        "                    \"amount\": {\"bsonType\": \"double\", \"minimum\": 0},\n",
        "                    \"currency\": {\"bsonType\": \"string\"},\n",
        "                    \"sender\": {\"bsonType\": \"string\"},\n",
        "                    \"receiver\": {\"bsonType\": \"string\"},\n",
        "                    \"compliance_status\": {\"bsonType\": \"string\"}\n",
        "                }\n",
        "            }\n",
        "        },\n",
        "        validationLevel=\"moderate\",\n",
        "    )\n",
        "    print(f\"Collection {TRANSACTIONS} created successfully\")\n",
        "  else:\n",
        "    print(f\"Collection {TRANSACTIONS} already exists\")\n",
        "\n",
        "\n",
        "  # Regulations collections\n",
        "  if REGULATIONS not in existing_collections:\n",
        "    db.create_collection(REGULATIONS)\n",
        "    print(f\"Collection {REGULATIONS} created successfully\")\n",
        "  else:\n",
        "    print(f\"Collection {REGULATIONS} already exists\")\n",
        "\n",
        "\n",
        "  # Checkpoints collections\n",
        "  if CHECKPOINTS not in existing_collections:\n",
        "    db.create_collection(CHECKPOINTS)\n",
        "    print(f\"Collection {CHECKPOINTS} created successfully\")\n",
        "  else:\n",
        "    print(f\"Collection {CHECKPOINTS} already exists\")\n",
        "\n",
        "  # Checkpoint Writes collection\n",
        "  if CHECKPOINTS_WRITES not in existing_collections:\n",
        "    db.create_collection(CHECKPOINTS_WRITES)\n",
        "    print(f\"Collection {CHECKPOINTS_WRITES} created successfully\")\n",
        "\n",
        "\n",
        "\n",
        "create_mongodb_collections()"
      ],
      "metadata": {
        "id": "IV0H80Q2I4AE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vector Search Index Creation\n",
        "\n",
        "In other to enable semantic search with embedded documents vectors, we need to\n",
        "enable a vector search index on the regulations collection.\n",
        "\n",
        "We're using cosine similarity because we're doing semantic search and document classification problems.\n",
        "\n",
        "see this for https://www.pinecone.io/learn/vector-similarity/\n",
        "\n",
        "\n",
        "We also poll for readyness after creating the search index as attempting search on unready index causes error"
      ],
      "metadata": {
        "id": "51Cg27WTLkdt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from pymongo.operations import SearchIndexModel\n",
        "\n",
        "VECTOR_INDEX_NAME = \"regulation_vector_index\"\n",
        "\n",
        "def create_vector_search_index():\n",
        "  try:\n",
        "    existing_regulation_indexes = regulations_collection.list_search_indexes()\n",
        "    for index in existing_regulation_indexes:\n",
        "      if index[\"name\"] == VECTOR_INDEX_NAME:\n",
        "        print(f\"Vector search index {VECTOR_INDEX_NAME} already exists\")\n",
        "        return\n",
        "  except Exception as e:\n",
        "    print(f\"Error getting indexes: {e}\")\n",
        "    return\n",
        "\n",
        "  #create new vector search index\n",
        "  search_index_model = SearchIndexModel(\n",
        "      definition={\n",
        "          \"fields\": [\n",
        "              {\n",
        "                  \"type\": \"vector\",\n",
        "                  \"path\": \"embedding\",\n",
        "                  \"similarity\": \"cosine\",\n",
        "                  \"numDimensions\": 1024\n",
        "              }\n",
        "          ]\n",
        "      },\n",
        "      name=VECTOR_INDEX_NAME,\n",
        "      type=\"vectorSearch\"\n",
        "  )\n",
        "\n",
        "  try:\n",
        "    new_search_index = regulations_collection.create_search_index(search_index_model)\n",
        "    print(f\"Vector search index {VECTOR_INDEX_NAME} created successfully and is building\")\n",
        "  except Exception as e:\n",
        "    print(f\"Error creating vector search index: {e}\")\n",
        "\n",
        "  #wait for sync\n",
        "  print(\"Polling to check if vector search index is ready\")\n",
        "  predicate = lambda i: i.get(\"queryable\") is True\n",
        "\n",
        "  while True:\n",
        "    try:\n",
        "      indexes = list(regulations_collection.list_search_indexes(new_search_index))\n",
        "      if indexes:\n",
        "        if predicate(indexes[0]):\n",
        "          break\n",
        "      time.sleep(5)\n",
        "    except Exception as e:\n",
        "      print(f\"Error polling for vector search index: {e}\")\n",
        "      break\n",
        "\n",
        "  print(f\"{new_search_index} is ready for querying.\")\n",
        "\n",
        "create_vector_search_index()"
      ],
      "metadata": {
        "id": "aCxGV_uJLa9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Document Processing and Schema Definition\n",
        "\n"
      ],
      "metadata": {
        "id": "-hT8iBRYWVLG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import re\n",
        "from datetime import datetime\n",
        "\n",
        "from docx import Document\n",
        "from pydantic import BaseModel, Field\n",
        "from pypdf import PdfReader\n",
        "from typing import Any, Dict, List, Optional, Union\n",
        "\n",
        "class RegulationDocument(BaseModel):\n",
        "  # Schema for regulatory Documents\n",
        "\n",
        "  id: Optional[str] = None\n",
        "  title: str\n",
        "  content: str\n",
        "  source: str\n",
        "  document_type: str\n",
        "  jurisdiction: str\n",
        "  publication_date: str\n",
        "  tags: List[str] = Field(default_factory=list)\n",
        "  embedding: Optional[List[float]] = None\n",
        "  chunks: Optional[List[Dict[str, Any]]] = None\n",
        "\n",
        "  def to_dict(self):\n",
        "    return self.model_dump(exclude_none=True)\n",
        "\n",
        "\n",
        "\n",
        "class DocumentProcessor:\n",
        "  \"\"\"Processes different document formats and extracts text\"\"\"\n",
        "\n",
        "  @staticmethod\n",
        "  def extract_text_from_pdf(file_path_or_bytes):\n",
        "    if isinstance(file_path_or_bytes, str):\n",
        "      reader = PdfReader(file_path_or_bytes)\n",
        "    else:\n",
        "      reader = PdfReader(io.BytesIO(file_path_or_bytes))\n",
        "\n",
        "    text = \"\"\n",
        "    for page in reader.pages:\n",
        "      text += page.extract_text() + \"\\n\"\n",
        "    return text\n",
        "\n",
        "  @staticmethod\n",
        "  def extract_text_from_docx(file_path_or_bytes):\n",
        "    if isinstance(file_path_or_bytes, str):\n",
        "      document = Document(file_path_or_bytes)\n",
        "    else:\n",
        "      document = Document(io.BytesIO(file_path_or_bytes))\n",
        "\n",
        "    text = \"\"\n",
        "    for paragraph in document.paragraphs:\n",
        "      text += paragraph + \"\\n\"\n",
        "    return text\n",
        "\n",
        "  @staticmethod\n",
        "  def extract_text_from_txt(file_path_or_bytes):\n",
        "    if isinstance(file_path_or_bytes, str):\n",
        "      with open(file_path_or_bytes, encoding=\"utf-8\") as f:\n",
        "        return f.read()\n",
        "    else:\n",
        "      return file_path_or_bytes.decode(\"utf-8\")\n",
        "\n",
        "\n",
        "  @staticmethod\n",
        "  def process_document(file_path, metadata=None):\n",
        "    if metadata is None:\n",
        "      metadata = {}\n",
        "\n",
        "    file_extension = file_path.split('.')[-1].lower()\n",
        "\n",
        "    if file_extension == \"pdf\":\n",
        "      text = DocumentProcessor.extract_text_from_pdf(file_path)\n",
        "      doc_type = \"pdf\"\n",
        "    elif file_extension == \"docx\":\n",
        "      text = DocumentProcessor.extract_text_from_docx(file_path)\n",
        "      doc_type  = \"docx\"\n",
        "    elif file_extension == \"txt\":\n",
        "      text = DocumentProcessor.extract_text_from_txt(file_path)\n",
        "      doc_type = \"txt\"\n",
        "    else:\n",
        "      raise ValueError(f\"Unsupported file format: {file_extension}\")\n",
        "\n",
        "    if \"title\" not in metadata:\n",
        "      title = os.path.basename(file_path).rsplit('.', 1)[0]\n",
        "      metadata[\"title\"] = title\n",
        "\n",
        "    if \"document_type\" not in metadata:\n",
        "      metadata[\"document_type\"] = doc_type\n",
        "\n",
        "    regulation = RegulationDocument(\n",
        "        title=metadata.get(\"title\", \"\"),\n",
        "        content=text,\n",
        "        source=metadata.get(\"source\", file_path),\n",
        "        document_type=metadata.get(\"document_type\", doc_type),\n",
        "        jurisdiction=metadata.get(\"jurisdiction\", \"Unknown\"),\n",
        "        publication_date=metadata.get(\n",
        "            \"publication_date\", datetime.now().strftime(\"%Y-%m-%d\")\n",
        "        ),\n",
        "        tags=metadata.get(\"tags\", []),\n",
        "    )\n",
        "\n",
        "    return regulation\n",
        "\n",
        "  @staticmethod\n",
        "  def extract_metadata_from_content(content):\n",
        "    metadata = {}\n",
        "\n",
        "    # Extract jurisdiction\n",
        "    jurisdiction_pattern = r\"(?i)jurisdiction[:\\s]+(\\w+(?:\\s+\\w+)*)\"\n",
        "    jurisdiction_match = re.search(jurisdiction_pattern, content)\n",
        "    if jurisdiction_match:\n",
        "        metadata[\"jurisdiction\"] = jurisdiction_match.group(1).strip()\n",
        "\n",
        "    # Extract date\n",
        "    date_pattern = r\"(?i)(?:date|published)[:\\s]+(\\d{1,2}[/-]\\d{1,2}[/-]\\d{2,4}|\\d{4}[/-]\\d{1,2}[/-]\\d{1,2})\"\n",
        "    date_match = re.search(date_pattern, content)\n",
        "    if date_match:\n",
        "        metadata[\"publication_date\"] = date_match.group(1).strip()\n",
        "\n",
        "    # Extract tags\n",
        "    tags_pattern = r\"(?i)(?:keywords|tags)[:\\s]+([\\w\\s,]+)\"\n",
        "    tags_match = re.search(tags_pattern, content)\n",
        "    if tags_match:\n",
        "        tags = [tag.strip() for tag in tags_match.group(1).split(\",\")]\n",
        "        metadata[\"tags\"] = tags\n",
        "\n",
        "    return metadata\n"
      ],
      "metadata": {
        "id": "fIY7SZn_TJg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text Processing, Embedding Generation and Storage\n",
        "\n",
        "A few notes:\n",
        "\n",
        "1. We implement both chunk level and document level embeddings.\n",
        "This is because it helps with hierarchical retreivel. This means we have a 2 staged retrivel process where we first find the relevant document before finding the relevant chunks within those documents\n",
        "\n",
        "2. We use langchains RecursiveCharacterTextSplitter to preserve semantics\n",
        "\n",
        "3. Proper rate limiting by tracking time between subsequent calls"
      ],
      "metadata": {
        "id": "Izg3NAA4dgkH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set_env_variables(\"VOYAGE_API_KEY\")"
      ],
      "metadata": {
        "id": "DQhISEdEfSDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import voyageai\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "\n",
        "class TextProcessor:\n",
        "\n",
        "  last_voyage_call = 0\n",
        "  _instance = None\n",
        "\n",
        "  # use singleton pattern to only have one instance throughout the app's lifetime\n",
        "  def __new__(cls, *args, **kwargs):\n",
        "    if cls._instance is None:\n",
        "      cls._instance = super().__new__(cls)\n",
        "      cls._instance._initialized = False\n",
        "    return cls._instance\n",
        "\n",
        "  def __init__(self, chunk_size=1000, chunk_overlap=200):\n",
        "    if not hasattr(self, '_initialized') or not self._initialized:\n",
        "      self.chunk_size = chunk_size\n",
        "      self.chunk_overlap = chunk_overlap\n",
        "      self.text_splitter = RecursiveCharacterTextSplitter(\n",
        "                chunk_size=chunk_size,\n",
        "                chunk_overlap=chunk_overlap,\n",
        "                length_function=len,\n",
        "                separators=[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\", \",\", \" \", \"\"],\n",
        "            )\n",
        "      self.voyage_client = voyageai.Client(api_key=os.environ[\"VOYAGE_API_KEY\"])\n",
        "      self.model_name = \"voyage-3\"\n",
        "      self._initialized = True\n",
        "\n",
        "  def chunk_text(self, text):\n",
        "    print(text)\n",
        "    return self.text_splitter.split_text(text)\n",
        "\n",
        "  def generate_embeddings(self, texts: List[str]):\n",
        "    if not texts:\n",
        "      return []\n",
        "\n",
        "    current_time = time.time()\n",
        "    time_since_last_call = current_time - self.last_voyage_call\n",
        "\n",
        "    if time_since_last_call < 20:\n",
        "      wait_time = 20 - time_since_last_call\n",
        "      print(\n",
        "          f\"Due to rate limiting, we're waiting {wait_time} seconds\"\n",
        "      )\n",
        "      time.sleep(wait_time)\n",
        "    embeddings = self.voyage_client.embed(texts, model=self.model_name).embeddings\n",
        "\n",
        "    self.last_voyage_call = time.time()\n",
        "    return embeddings\n",
        "\n",
        "  def process_document(self, regulation_doc):\n",
        "    chunks = self.chunk_text(regulation_doc.content)\n",
        "    chunk_embeddings = self.generate_embeddings(chunks)\n",
        "    processed_chunks = []\n",
        "\n",
        "    for i, (chunk, embedding) in enumerate(zip(chunks, chunk_embeddings)):\n",
        "      processed_chunks.append({\n",
        "          \"chunk_id\": i,\n",
        "          \"content\": chunk,\n",
        "          \"embedding\": embedding\n",
        "      })\n",
        "\n",
        "    doc_text = f\"{regulation_doc.title}\\n{chunks[0] if chunks else ''}\"\n",
        "    doc_embedding = self.generate_embeddings(doc_text)[0]\n",
        "\n",
        "    regulation_doc.embedding = doc_embedding\n",
        "    regulation_doc.chunks = processed_chunks\n",
        "\n",
        "    return regulation_doc\n",
        "\n",
        "  def store_regulation(self, regulation_doc):\n",
        "    regulation_dict = regulation_doc.to_dict()\n",
        "\n",
        "    result = regulations_collection.insert_one(regulation_dict)\n",
        "    print(f\"Stored regulation document with ID: {result.inserted_id}\")\n",
        "\n",
        "    return result.inserted_id\n"
      ],
      "metadata": {
        "id": "isuBh4VzdgQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample regulatory texts\n",
        "sample_regulations = [\n",
        "    {\n",
        "        \"title\": \"Anti-Money Laundering Directive\",\n",
        "        \"content\": \"\"\"ANTI-MONEY LAUNDERING DIRECTIVE\n",
        "Jurisdiction: European Union\n",
        "Date: 2021-06-15\n",
        "Keywords: AML, KYC, financial crime, cross-border\n",
        "\n",
        "Section 1: Scope and Definitions\n",
        "1.1 This directive applies to all financial institutions operating within the European Union that process cross-border transactions.\n",
        "1.2 'Cross-border transaction' refers to any financial transfer that originates in one country and terminates in another.\n",
        "1.3 'High-risk jurisdiction' refers to countries identified by the Financial Action Task Force (FATF) as having strategic deficiencies in their AML/CFT regimes.\n",
        "\n",
        "Section 2: Due Diligence Requirements\n",
        "2.1 Enhanced due diligence must be performed for all transactions exceeding €10,000 that involve high-risk jurisdictions.\n",
        "2.2 Financial institutions must verify the identity of both the sender and recipient for all cross-border transactions exceeding €3,000.\n",
        "2.3 For transactions with sanctioned countries, prior approval must be obtained from the compliance department.\n",
        "\n",
        "Section 3: Reporting Requirements\n",
        "3.1 All suspicious transactions must be reported to the national Financial Intelligence Unit within 24 hours of detection.\n",
        "3.2 Monthly reports must be submitted detailing all cross-border transactions exceeding €50,000.\n",
        "3.3 Failure to report suspicious activities may result in fines of up to €5 million or 10% of annual turnover.\n",
        "\"\"\",\n",
        "        \"source\": \"EU Financial Regulatory Authority\",\n",
        "        \"document_type\": \"directive\",\n",
        "        \"jurisdiction\": \"European Union\",\n",
        "        \"publication_date\": \"2021-06-15\",\n",
        "        \"tags\": [\"AML\", \"KYC\", \"financial crime\", \"cross-border\"],\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"Sanctions Compliance Framework\",\n",
        "        \"content\": \"\"\"SANCTIONS COMPLIANCE FRAMEWORK\n",
        "Jurisdiction: United States\n",
        "Date: 2022-03-10\n",
        "Keywords: sanctions, OFAC, restricted parties, compliance\n",
        "\n",
        "Section 1: Overview\n",
        "1.1 This framework outlines compliance requirements for financial institutions regarding transactions subject to sanctions administered by the Office of Foreign Assets Control (OFAC).\n",
        "1.2 All US financial institutions and their foreign branches must comply with these requirements.\n",
        "\n",
        "Section 2: Prohibited Transactions\n",
        "2.1 No financial institution shall process transactions involving entities listed on the Specially Designated Nationals (SDN) list.\n",
        "2.2 Transactions with entities in comprehensively sanctioned countries including Iran, North Korea, Syria, Cuba, and the Crimea region are prohibited without specific OFAC authorization.\n",
        "2.3 Transactions that attempt to circumvent sanctions through third-party intermediaries are strictly prohibited and subject to severe penalties.\n",
        "\n",
        "Section 3: Screening Requirements\n",
        "3.1 All parties to a transaction must be screened against the most current OFAC sanctions lists prior to processing.\n",
        "3.2 Screening must include beneficial owners with 25% or greater ownership interest.\n",
        "3.3 Institutions must implement real-time screening for all international wire transfers regardless of amount.\n",
        "\n",
        "Section 4: Penalties for Non-Compliance\n",
        "4.1 Civil penalties may reach the greater of $1,000,000 per violation or twice the value of the transaction.\n",
        "4.2 Criminal penalties for willful violations may include fines up to $20 million and imprisonment up to 30 years.\n",
        "4.3 Financial institutions may be subject to regulatory actions including restrictions on activities or loss of licenses.\n",
        "\"\"\",\n",
        "        \"source\": \"US Department of Treasury\",\n",
        "        \"document_type\": \"framework\",\n",
        "        \"jurisdiction\": \"United States\",\n",
        "        \"publication_date\": \"2022-03-10\",\n",
        "        \"tags\": [\"sanctions\", \"OFAC\", \"restricted parties\", \"compliance\"],\n",
        "    },\n",
        "]"
      ],
      "metadata": {
        "id": "wquJXgfcm355"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_processor = TextProcessor()\n",
        "\n",
        "for reg_data in sample_regulations:\n",
        "  regulation = RegulationDocument(**reg_data)\n",
        "\n",
        "  processed_regulation = text_processor.process_document(regulation)\n",
        "  regulation_id = text_processor.store_regulation(processed_regulation)\n",
        "\n",
        "  print(f\"Processed and stored regulation: {regulation.title}\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "eduMThZplBod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transaction Data Models and Compliance Status\n",
        "\n"
      ],
      "metadata": {
        "id": "BbbvQaTHppxQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from enum import Enum\n",
        "from typing import Any, Dict, Optional\n",
        "\n",
        "from pydantic import BaseModel,  field_validator\n",
        "\n",
        "class ComplianceStaus(str, Enum):\n",
        "  COMPLIANT = \"Compliant\"\n",
        "  REPORTING_REQUIRED = \"Reporting Required\"\n",
        "  VIOLATION = \"Violation\"\n",
        "  PENDING = \"Pending Assessment\"\n",
        "\n",
        "\n",
        "class TransactionParty(BaseModel):\n",
        "  name: str\n",
        "  country: str\n",
        "  account_number: str\n",
        "  institution: str\n",
        "  is_sanctioned: bool = False\n",
        "  risk_score: Optional[float] = None\n",
        "\n",
        "class Transaction(BaseModel):\n",
        "  id: Optional[str] = None\n",
        "  transaction_id: str\n",
        "  amount: float\n",
        "  currency: str\n",
        "  sender: TransactionParty\n",
        "  receiver: TransactionParty\n",
        "  transaction_date: str\n",
        "  transaction_type: str\n",
        "  description: str\n",
        "  compliance_status: ComplianceStaus = ComplianceStaus.PENDING\n",
        "  compliance_details: Optional[Dict[str, Any]] = None\n",
        "\n",
        "  @field_validator(\"amount\")\n",
        "  def amount_must_be_positive(cls, v):\n",
        "    if v <= 0:\n",
        "      raise ValueError(\"Amount must be positive\")\n",
        "    return v\n",
        "\n",
        "  def to_dict(self):\n",
        "    return self.model_dump(exclude_none=True)\n",
        "\n",
        "  def to_prompt(self):\n",
        "    return f\"\"\"Transaction Details:\n",
        "      - Transaction ID: {self.transaction_id}\n",
        "      - Amount: {self.amount} {self.currency}\n",
        "      - Date: {self.transaction_date}\n",
        "      - Type: {self.transaction_type}\n",
        "      - Description: {self.description}\n",
        "\n",
        "      Sender Information:\n",
        "      - Name: {self.sender.name}\n",
        "      - Country: {self.sender.country}\n",
        "      - Institution: {self.sender.institution}\n",
        "      - Sanctioned: {self.sender.is_sanctioned}\n",
        "\n",
        "      Receiver Information:\n",
        "      - Name: {self.receiver.name}\n",
        "      - Country: {self.receiver.country}\n",
        "      - Institution: {self.receiver.institution}\n",
        "      - Sanctioned: {self.receiver.is_sanctioned}\n",
        "    \"\"\"\n",
        "\n"
      ],
      "metadata": {
        "id": "wofSSfJHpwYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compliance monitoring engine and workflow orchestrator\n",
        "\n",
        "We use the following:\n",
        "\n",
        "1. HF ShiledGemma: For classification\n",
        "2. MongoDb Atlas for vector search, checkpoints and transaction storage\n",
        "3. Voyage AI for generating text embeddings\n",
        "4. LangGraph for stateful  workflow orchestration\n",
        "\n",
        "\n",
        "Compliance Engine:\n",
        "1. Retrieves relevant regulation associated with transaction via vector ssearch\n",
        "2. checks compliance assesment using LLM and returns JSON\n",
        "3. Normalize confidence score using an activation fn -> softmax\n",
        "4. updates transaction records with compliance status and details\n",
        "\n",
        "\n",
        "Compliance Workflow:\n",
        "1. Defines a LangGraph based workflow for processing transactions\n",
        "2. Includes checkpointing, error handling and conditional retries\n"
      ],
      "metadata": {
        "id": "dsMZiH9qrdhU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set_env_variables(\"HUGGINGFACE_API_KEY\")"
      ],
      "metadata": {
        "id": "NK5zy7mks4Xp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from huggingface_hub import login\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_huggingface import HuggingFacePipeline\n",
        "from torch.nn.functional import softmax\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "\n",
        "class ComplianceEngine:\n",
        "\n",
        "  MODEL = \"google/shieldgemma-2b\"\n",
        "\n",
        "  def __init__(self):\n",
        "    login(token=os.environ.get(\"HUGGINGFACE_API_KEY\"))\n",
        "    self.tokenizer = AutoTokenizer.from_pretrained(self.MODEL)\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        self.MODEL,\n",
        "        torch_dtype=torch.bfloat16,\n",
        "        device_map=\"auto\"\n",
        "    )\n",
        "\n",
        "    text_generation_pipeline = pipeline(\n",
        "        \"text-generation\",\n",
        "        model=model,\n",
        "        tokenizer = self.tokenizer,\n",
        "        max_new_tokens=1024,\n",
        "        do_sample=False,\n",
        "        pad_token_id=self.tokenizer.eos_token_id #https://github.com/huggingface/transformers/issues/34869\n",
        "    )\n",
        "\n",
        "    self.llm = HuggingFacePipeline(pipeline=text_generation_pipeline)\n",
        "\n",
        "    self.text_processor = TextProcessor()\n",
        "\n",
        "    self.assessment_prompt = ChatPromptTemplate.from_template(\n",
        "        \"\"\"You are a financial compliance expert with extensive knowledge of regulatory frameworks. Your task is to evaluate whether the following transaction complies with the specified regulations.\n",
        "\n",
        "    Transaction Details:\n",
        "    {transaction}\n",
        "\n",
        "    Relevant Regulations:\n",
        "    {regulations}\n",
        "\n",
        "    Compliance Assessment Framework:\n",
        "    - Compliant: Transaction fully adheres to all applicable regulations with no reporting requirements\n",
        "    - Reporting Required: Transaction is legal but requires mandatory reporting to regulatory authorities\n",
        "    - Violation: Transaction directly contravenes one or more regulatory requirements\n",
        "\n",
        "    Step-by-step Analysis Process:\n",
        "    1. Identify the transaction type and key participants\n",
        "    2. Determine which specific regulations apply to this transaction\n",
        "    3. Assess compliance with each applicable regulation\n",
        "    4. Evaluate if reporting requirements exist\n",
        "    5. Determine final compliance status\n",
        "\n",
        "    Provide your assessment in the following JSON format:\n",
        "    {{\n",
        "        \"status\": \"Compliant\" | \"Reporting Required\" | \"Violation\",\n",
        "        \"confidence\": <float between 0 and 1>,\n",
        "        \"reasoning\": \"<concise explanation with specific regulatory references>\",\n",
        "        \"applicable_regulations\": [\"<specific regulation sections that apply>\"],\n",
        "        \"recommended_actions\": [\"<actionable steps for compliance>\"],\n",
        "        \"risk_factors\": [\"<key risk elements identified>\"]\n",
        "    }}\n",
        "\n",
        "    Return ONLY the JSON object. No additional text, explanations, or formatting. YOU WILL BE PENALIZED IF YOU RETURN ANYTHING OTHER THAN THE JSON.\n",
        "    \"\"\"\n",
        "    )\n",
        "\n",
        "    self.parser = JsonOutputParser()\n",
        "\n",
        "    # creates chain\n",
        "    self.chain = self.assessment_prompt | self.llm | self.parser\n",
        "\n",
        "\n",
        "  def retrieve_relevant_regulations(self, transaction: Transaction):\n",
        "    transaction_text = transaction.to_prompt()\n",
        "    transaction_embedding = self.text_processor.generate_embeddings(\n",
        "        [transaction_text]\n",
        "    )[0]\n",
        "\n",
        "    vector_search_stage = {\n",
        "        \"$vectorSearch\": {\n",
        "            \"index\": VECTOR_INDEX_NAME,\n",
        "            \"queryVector\": transaction_embedding,\n",
        "            \"path\": \"embedding\",\n",
        "            \"numCandidates\": 150,\n",
        "            \"limit\": 5\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Remove embedding, _id and chunks from result. As they're not neccessary at this point\n",
        "    project_stage = {\n",
        "        \"$project\":{\n",
        "            \"embedding\": 0,\n",
        "            \"chunks\": 0,\n",
        "            \"_id\": 0\n",
        "        }\n",
        "    }\n",
        "\n",
        "    pipeline = [vector_search_stage, project_stage]\n",
        "    results = list(regulations_collection.aggregate(pipeline))\n",
        "\n",
        "    regulations_text = \"\"\n",
        "    for i, reg in enumerate(results, 1):\n",
        "      regulations_text += f\"Regulation {i}: {reg['title']} ({reg['jurisdiction']}, {reg['publication_date']})\\n\"\n",
        "      regulations_text += f\"{reg['content']}\\n\\n\"\n",
        "\n",
        "    return regulations_text\n",
        "\n",
        "\n",
        "  def apply_softmax_normalization(self, assessment):\n",
        "    status_scores = {\"Compliant\": 0.0, \"Reporting Required\": 0.0, \"Violation\": 0.0}\n",
        "\n",
        "    status_scores[assessment[\"status\"]] = assessment[\"confidence\"]\n",
        "\n",
        "    scores_array = np.array(list(status_scores.values()))\n",
        "    normalized_scores = softmax(torch.tensor(scores_array), dim=0).numpy()\n",
        "\n",
        "    assessment[\"confidence\"] = float(\n",
        "            normalized_scores[list(status_scores.keys()).index(assessment[\"status\"])]\n",
        "    )\n",
        "\n",
        "    assessment[\"confidence_details\"] = {\n",
        "        status: float(score)\n",
        "        for status, score in zip(status_scores.keys(), normalized_scores)\n",
        "    }\n",
        "\n",
        "    return assessment\n",
        "\n",
        "  def assess_transaction(self, transaction: Transaction):\n",
        "    try:\n",
        "      regulations = self.retrieve_relevant_regulations(transaction)\n",
        "      print(\"-\" * 80)\n",
        "      print(f\"Retrieved {len(regulations)} relevant regulations.\")\n",
        "      print(\"Here are the first 100 characters of the first regulation:\")\n",
        "      print(regulations.split(\"\\n\")[0][:100])\n",
        "\n",
        "      inputs = {\n",
        "          \"transaction\": transaction.to_prompt(),\n",
        "          \"regulations\": regulations\n",
        "      }\n",
        "      print(\"before invoking chain\")\n",
        "      assessment = self.chain.invoke(inputs)\n",
        "      print(\"after invoking chain\")\n",
        "\n",
        "      assessment = self.apply_softmax_normalization(assessment)\n",
        "      print(\"after invoking apply_softmax_normalization\")\n",
        "\n",
        "      transaction.compliance_status = ComplianceStaus(assessment[\"status\"])\n",
        "      transaction.compliance_details = assessment\n",
        "\n",
        "      if transaction.id:\n",
        "        transaction_collection.update_one(\n",
        "            {\"_id\": transaction.id}, {\"$set\": transaction.to_dict()}\n",
        "        )\n",
        "        print(f\"Update transaction with ID: {transaction.id}\")\n",
        "      else:\n",
        "        result = transaction_collection.insert_one(transaction.to_dict())\n",
        "        transaction.id = str(result.inserted_id)\n",
        "        print(f\"Stored transaction with ID: {transaction.id}\")\n",
        "\n",
        "      return assessment\n",
        "\n",
        "    except Exception as e:\n",
        "      print(f\"Error during Langchain processing: {e}\")\n",
        "      assessment = {\n",
        "          \"status\": \"Reporting Required\",\n",
        "          \"confidence\": 0.5,\n",
        "          \"reasoning\": f\"Error during assessment: {e!s}. Please review the transaction manually.\",\n",
        "          \"applicable_regulations\": [],\n",
        "          \"recommended_actions\": [\"Review transaction manually\"],\n",
        "          \"risk_factors\": [\"Assessment processing failure\"],\n",
        "      }\n",
        "      return assessment\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3a443XT3rmT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMplement Agent Orchestration with Langraph to coordinate the compliance assessment workflow"
      ],
      "metadata": {
        "id": "n13muvqx3NhO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Any, Dict, List, Optional, TypedDict\n",
        "\n",
        "import langgraph.graph as lg\n",
        "from langchain_core.messages import AIMessage, HumanMessage\n",
        "from langgraph.checkpoint.mongodb import MongoDBSaver\n",
        "\n",
        "\n",
        "# Graphs state\n",
        "class ComplianceState(TypedDict):\n",
        "  transaction: Dict[str, Any]\n",
        "  regulations: Optional[List[Dict[str, Any]]]\n",
        "  assessment: Optional[Dict[str, Any]]\n",
        "  messages: List[Union[HumanMessage, AIMessage]]\n",
        "  errors: Optional[List[str]]\n",
        "\n",
        "class ComplianceWorkflow:\n",
        "\n",
        "  def __init__(self):\n",
        "    self.compliance_engine = ComplianceEngine()\n",
        "    self.text_processor = TextProcessor()\n",
        "\n",
        "    self.checkpoint_store = MongoDBSaver(client, DB_NAME, CHECKPOINTS)\n",
        "\n",
        "    self.workflow = self._build_graph()\n",
        "\n",
        "  def _parse_transaction(self, state:ComplianceState) -> ComplianceState:\n",
        "    try:\n",
        "      transaction_data = state[\"transaction\"]\n",
        "      transaction = Transaction(**transaction_data)\n",
        "\n",
        "      state[\"transaction\"] = transaction.to_dict()\n",
        "      state[\"messages\"].append(\n",
        "          AIMessage(content=f\"Transaction {transaction.transaction_id} parsed successfully.\")\n",
        "      )\n",
        "    except Exception as e:\n",
        "      error_msg = f\"Error parsing transaction: {e!s}\"\n",
        "      state[\"errors\"] = state.get(\"errors\", []) + [error_msg]\n",
        "      state[\"messages\"].append(AIMessage(content=error_msg))\n",
        "\n",
        "    return state\n",
        "\n",
        "  def _retrieve_regulations(self, state: ComplianceState) -> ComplianceState:\n",
        "    try:\n",
        "      transaction_data = state[\"transaction\"]\n",
        "      transaction = Transaction(**transaction_data)\n",
        "\n",
        "      regulations_text = self.compliance_engine.retrieve_relevant_regulations(\n",
        "          transaction\n",
        "      )\n",
        "\n",
        "      state[\"regulations\"] = regulations_text\n",
        "      state[\"messages\"].append(\n",
        "          AIMessage(content=\"Retrieved relevant regulations for compliance assessment\")\n",
        "      )\n",
        "\n",
        "    except Exception as e:\n",
        "      error_msg = f\"Error retrieving regulations: {e!s}\"\n",
        "      state[\"errors\"] = state.get(\"errors\", []) + [error_msg]\n",
        "      state[\"messages\"].append(AIMessage(content=error_msg))\n",
        "\n",
        "    return state\n",
        "\n",
        "  def _assess_compliance(self, state: ComplianceState) -> ComplianceState:\n",
        "    try:\n",
        "      transaction_data = state[\"transaction\"]\n",
        "      transaction = Transaction(**transaction_data)\n",
        "\n",
        "      assessment = self.compliance_engine.assess_transaction(transaction)\n",
        "\n",
        "      state[\"assessment\"] = assessment\n",
        "      state[\"transaction\"] = (\n",
        "          transaction.to_dict()\n",
        "      )\n",
        "      summary = f\"Compliance assessment complete. Status: {assessment['status']} (Confidence: {assessment['confidence']:.2f})\\n\"\n",
        "      summary += f\"Reasoning: {assessment['reasoning']} \\n\"\n",
        "      if assessment.get(\"recommended_actions\"):\n",
        "        summary += f\"Recommended actions: {', '.join(assessment['recommended_actions'])}\\n\"\n",
        "\n",
        "      state[\"messages\"].append(AIMessage(content=summary))\n",
        "    except Exception as e:\n",
        "        error_msg = f\"Error assessing compliance: {e!s}\"\n",
        "        state[\"errors\"] = state.get(\"errors\", []) + [error_msg]\n",
        "        state[\"messages\"].append(AIMessage(content=error_msg))\n",
        "\n",
        "    return state\n",
        "\n",
        "  def _should_retry(self, state: ComplianceState) -> str:\n",
        "    if state.get(\"errors\") and len(state[\"errors\"]) < 3:\n",
        "        return \"retry\"\n",
        "    return \"end\"\n",
        "\n",
        "  def _build_graph(self):\n",
        "\n",
        "    builder = lg.StateGraph(ComplianceState)\n",
        "\n",
        "    # nodes\n",
        "    builder.add_node(\"parse_transaction\", self._parse_transaction)\n",
        "    builder.add_node(\"retrieve_regulations\", self._retrieve_regulations)\n",
        "    builder.add_node(\"assess_compliance\", self._assess_compliance)\n",
        "\n",
        "    # edges\n",
        "    builder.add_edge(\"parse_transaction\", \"retrieve_regulations\")\n",
        "    builder.add_edge(\"retrieve_regulations\", \"assess_compliance\")\n",
        "\n",
        "    # conditional edge for error handling\n",
        "    builder.add_conditional_edges(\n",
        "        \"assess_compliance\",\n",
        "        self._should_retry,\n",
        "        {\"retry\": \"parse_transaction\", \"end\": lg.END}\n",
        "    )\n",
        "\n",
        "    builder.set_entry_point(\"parse_transaction\")\n",
        "\n",
        "    return builder.compile(checkpointer=self.checkpoint_store)\n",
        "\n",
        "  def process_transaction(self, transaction_data: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    initial_state = ComplianceState(\n",
        "        transaction=transaction_data,\n",
        "        regulations=None,\n",
        "        assessment=None,\n",
        "        messages=[\n",
        "            HumanMessage(\n",
        "                content=f\"Process transaction {transaction_data.get('transaction_id', 'unknown')}\"\n",
        "            )\n",
        "        ],\n",
        "        errors=None,\n",
        "    )\n",
        "\n",
        "    config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
        "    final_state = self.workflow.invoke(initial_state, config)\n",
        "\n",
        "    return final_state\n"
      ],
      "metadata": {
        "id": "keXDumM33VPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample transactions for demonstration\n",
        "sample_transactions = [\n",
        "    {\n",
        "        \"transaction_id\": \"TX123456789\",\n",
        "        \"amount\": 150000.00,\n",
        "        \"currency\": \"EUR\",\n",
        "        \"sender\": {\n",
        "            \"name\": \"European Trading Ltd\",\n",
        "            \"country\": \"Germany\",\n",
        "            \"account_number\": \"DE89370400440532013000\",\n",
        "            \"institution\": \"Deutsche Bank\",\n",
        "            \"is_sanctioned\": False,\n",
        "        },\n",
        "        \"receiver\": {\n",
        "            \"name\": \"Global Imports Inc\",\n",
        "            \"country\": \"United States\",\n",
        "            \"account_number\": \"US12345678901234567890\",\n",
        "            \"institution\": \"Bank of America\",\n",
        "            \"is_sanctioned\": False,\n",
        "        },\n",
        "        \"transaction_date\": \"2023-11-15\",\n",
        "        \"transaction_type\": \"International Wire Transfer\",\n",
        "        \"description\": \"Payment for machinery parts\",\n",
        "    },\n",
        "    {\n",
        "        \"transaction_id\": \"TX987654321\",\n",
        "        \"amount\": 75000.00,\n",
        "        \"currency\": \"USD\",\n",
        "        \"sender\": {\n",
        "            \"name\": \"American Exports LLC\",\n",
        "            \"country\": \"United States\",\n",
        "            \"account_number\": \"US98765432109876543210\",\n",
        "            \"institution\": \"JP Morgan Chase\",\n",
        "            \"is_sanctioned\": False,\n",
        "        },\n",
        "        \"receiver\": {\n",
        "            \"name\": \"Tehran Trading Co\",\n",
        "            \"country\": \"Iran\",\n",
        "            \"account_number\": \"IR123456789012345678901234\",\n",
        "            \"institution\": \"Bank Melli Iran\",\n",
        "            \"is_sanctioned\": True,\n",
        "        },\n",
        "        \"transaction_date\": \"2023-12-01\",\n",
        "        \"transaction_type\": \"International Wire Transfer\",\n",
        "        \"description\": \"Consulting services\",\n",
        "    },\n",
        "]"
      ],
      "metadata": {
        "id": "K1o4L8GfAuPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "workflow = ComplianceWorkflow()\n",
        "\n",
        "results = []\n",
        "for tx_data in sample_transactions:\n",
        "    print(f\"\\nProcessing transaction {tx_data['transaction_id']}...\")\n",
        "    result = workflow.process_transaction(tx_data)\n",
        "    results.append(result)\n",
        "\n",
        "    for message in result[\"messages\"]:\n",
        "        if isinstance(message, AIMessage):\n",
        "            print(f\"System: {message.content}\")\n",
        "\n",
        "    if result.get(\"assessment\"):\n",
        "        assessment = result[\"assessment\"]\n",
        "        print(f\"\\nFinal Assessment for {tx_data['transaction_id']}:\")\n",
        "        print(f\"Status: {assessment['status']}\")\n",
        "        print(f\"Confidence: {assessment['confidence']:.2f}\")\n",
        "        print(f\"Reasoning: {assessment['reasoning']}\")\n",
        "        if assessment.get(\"risk_factors\"):\n",
        "            print(f\"Risk Factors: {', '.join(assessment['risk_factors'])}\")\n",
        "        if assessment.get(\"applicable_regulations\"):\n",
        "            print(\n",
        "                f\"Applicable Regulations: {', '.join(assessment['applicable_regulations'])}\"\n",
        "            )\n",
        "        if assessment.get(\"recommended_actions\"):\n",
        "            print(\n",
        "                f\"Recommended Actions: {', '.join(assessment['recommended_actions'])}\"\n",
        "            )\n",
        "        print(\"-\" * 80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "799acf87553e4e878217139fed6136b4",
            "e4f0ccf22d85492dace13d7b85c2d029",
            "9474ddb0034146a29e4a69b8b8c02dab",
            "11d2eedb77944c908a8f2879b2d3637b",
            "952b1feccb2c41c590ba80a2d943c325",
            "28872541b14e41e8858be64a14724414",
            "fa089ae791674e2192f3630a01c8a208",
            "74266304df9d4ccda7a7bb35ced5eab2",
            "225d08b9e58746af8cba448c62055e7d",
            "f871b019e361494eace08c342baffd60",
            "f7b8367824bf420fb8a41eb1d1c7a285"
          ]
        },
        "id": "mHGUMebcAzmT",
        "outputId": "9e9ac1ef-fadc-406d-eebd-dc58c0e47ca9"
      },
      "execution_count": 36,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/accelerate/utils/modeling.py:1569: UserWarning: Current model requires 256 bytes of buffer for offloaded layers, which seems does not fit any GPU's remaining memory. If you are experiencing a OOM later, please consider using offload_buffers=True.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "799acf87553e4e878217139fed6136b4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processing transaction TX123456789...\n",
            "Due to rate limiting, we're waiting 19.31210160255432 seconds\n",
            "--------------------------------------------------------------------------------\n",
            "Retrieved 7789 relevant regulations.\n",
            "Here are the first 100 characters of the first regulation:\n",
            "Regulation 1: Anti-Money Laundering Directive (European Union, 2021-06-15)\n",
            "before invoking chain\n",
            "after invoking chain\n",
            "after invoking apply_softmax_normalization\n",
            "Error during Langchain processing: Document failed validation, full error: {'index': 0, 'code': 121, 'errmsg': 'Document failed validation', 'errInfo': {'failingDocumentId': ObjectId('682350ae8fc97133b9f004ea'), 'details': {'operatorName': '$jsonSchema', 'schemaRulesNotSatisfied': [{'operatorName': 'properties', 'propertiesNotSatisfied': [{'propertyName': 'sender', 'details': [{'operatorName': 'bsonType', 'specifiedAs': {'bsonType': 'string'}, 'reason': 'type did not match', 'consideredValue': {'name': 'European Trading Ltd', 'country': 'Germany', 'account_number': 'DE89370400440532013000', 'institution': 'Deutsche Bank', 'is_sanctioned': False}, 'consideredType': 'object'}]}, {'propertyName': 'receiver', 'details': [{'operatorName': 'bsonType', 'specifiedAs': {'bsonType': 'string'}, 'reason': 'type did not match', 'consideredValue': {'name': 'Global Imports Inc', 'country': 'United States', 'account_number': 'US12345678901234567890', 'institution': 'Bank of America', 'is_sanctioned': False}, 'consideredType': 'object'}]}]}]}}}\n",
            "System: Transaction TX123456789 parsed successfully.\n",
            "System: Retrieved relevant regulations for compliance assessment\n",
            "System: Compliance assessment complete. Status: Reporting Required (Confidence: 0.50)\n",
            "Reasoning: Error during assessment: Document failed validation, full error: {'index': 0, 'code': 121, 'errmsg': 'Document failed validation', 'errInfo': {'failingDocumentId': ObjectId('682350ae8fc97133b9f004ea'), 'details': {'operatorName': '$jsonSchema', 'schemaRulesNotSatisfied': [{'operatorName': 'properties', 'propertiesNotSatisfied': [{'propertyName': 'sender', 'details': [{'operatorName': 'bsonType', 'specifiedAs': {'bsonType': 'string'}, 'reason': 'type did not match', 'consideredValue': {'name': 'European Trading Ltd', 'country': 'Germany', 'account_number': 'DE89370400440532013000', 'institution': 'Deutsche Bank', 'is_sanctioned': False}, 'consideredType': 'object'}]}, {'propertyName': 'receiver', 'details': [{'operatorName': 'bsonType', 'specifiedAs': {'bsonType': 'string'}, 'reason': 'type did not match', 'consideredValue': {'name': 'Global Imports Inc', 'country': 'United States', 'account_number': 'US12345678901234567890', 'institution': 'Bank of America', 'is_sanctioned': False}, 'consideredType': 'object'}]}]}]}}}. Please review the transaction manually. \n",
            "Recommended actions: Review transaction manually\n",
            "\n",
            "\n",
            "Final Assessment for TX123456789:\n",
            "Status: Reporting Required\n",
            "Confidence: 0.50\n",
            "Reasoning: Error during assessment: Document failed validation, full error: {'index': 0, 'code': 121, 'errmsg': 'Document failed validation', 'errInfo': {'failingDocumentId': ObjectId('682350ae8fc97133b9f004ea'), 'details': {'operatorName': '$jsonSchema', 'schemaRulesNotSatisfied': [{'operatorName': 'properties', 'propertiesNotSatisfied': [{'propertyName': 'sender', 'details': [{'operatorName': 'bsonType', 'specifiedAs': {'bsonType': 'string'}, 'reason': 'type did not match', 'consideredValue': {'name': 'European Trading Ltd', 'country': 'Germany', 'account_number': 'DE89370400440532013000', 'institution': 'Deutsche Bank', 'is_sanctioned': False}, 'consideredType': 'object'}]}, {'propertyName': 'receiver', 'details': [{'operatorName': 'bsonType', 'specifiedAs': {'bsonType': 'string'}, 'reason': 'type did not match', 'consideredValue': {'name': 'Global Imports Inc', 'country': 'United States', 'account_number': 'US12345678901234567890', 'institution': 'Bank of America', 'is_sanctioned': False}, 'consideredType': 'object'}]}]}]}}}. Please review the transaction manually.\n",
            "Risk Factors: Assessment processing failure\n",
            "Recommended Actions: Review transaction manually\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Processing transaction TX987654321...\n",
            "Due to rate limiting, we're waiting 19.847891569137573 seconds\n",
            "--------------------------------------------------------------------------------\n",
            "Retrieved 8106 relevant regulations.\n",
            "Here are the first 100 characters of the first regulation:\n",
            "Regulation 1: Sanctions Compliance Framework (United States, 2022-03-10)\n",
            "before invoking chain\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-c8dba1f57448>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtx_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msample_transactions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nProcessing transaction {tx_data['transaction_id']}...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mworkflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_transaction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtx_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-26beed1ab72a>\u001b[0m in \u001b[0;36mprocess_transaction\u001b[0;34m(self, transaction_data)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"configurable\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"thread_id\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"2\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0mfinal_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfinal_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, **kwargs)\u001b[0m\n\u001b[1;32m   2821\u001b[0m         \u001b[0minterrupts\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInterrupt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2823\u001b[0;31m         for chunk in self.stream(\n\u001b[0m\u001b[1;32m   2824\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2825\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[0m\n\u001b[1;32m   2459\u001b[0m                 \u001b[0;31m# with channel updates applied only at the transition between steps.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2460\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2461\u001b[0;31m                     for _ in runner.tick(\n\u001b[0m\u001b[1;32m   2462\u001b[0m                         \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2463\u001b[0m                         \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/runner.py\u001b[0m in \u001b[0;36mtick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                 run_with_retry(\n\u001b[0m\u001b[1;32m    154\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                     \u001b[0mretry_policy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/retry.py\u001b[0m in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;31m# run the task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mParentCommand\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONF\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONFIG_KEY_CHECKPOINT_NS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/utils/runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    621\u001b[0m                     \u001b[0;31m# run in context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mset_config_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m                         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    624\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/utils/runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    375\u001b[0m                 \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecurse\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRunnable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-26beed1ab72a>\u001b[0m in \u001b[0;36m_assess_compliance\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mtransaction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransaction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtransaction_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m       \u001b[0massessment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompliance_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massess_transaction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransaction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m       \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"assessment\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massessment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-4f7a37e94420>\u001b[0m in \u001b[0;36massess_transaction\u001b[0;34m(self, transaction)\u001b[0m\n\u001b[1;32m    143\u001b[0m       }\n\u001b[1;32m    144\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"before invoking chain\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m       \u001b[0massessment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"after invoking chain\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3032\u001b[0m                         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3033\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3034\u001b[0;31m                         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3035\u001b[0m         \u001b[0;31m# finish the root run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3036\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         return (\n\u001b[0;32m--> 387\u001b[0;31m             self.generate_prompt(\n\u001b[0m\u001b[1;32m    388\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    762\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    763\u001b[0m         \u001b[0mprompt_strings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_strings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    969\u001b[0m                 )\n\u001b[1;32m    970\u001b[0m             ]\n\u001b[0;32m--> 971\u001b[0;31m             return self._generate_helper(\n\u001b[0m\u001b[1;32m    972\u001b[0m                 \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    788\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m             output = (\n\u001b[0;32m--> 790\u001b[0;31m                 self._generate(\n\u001b[0m\u001b[1;32m    791\u001b[0m                     \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m                     \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_huggingface/llms/huggingface_pipeline.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;31m# Process batch of prompts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m             responses = self.pipeline(\n\u001b[0m\u001b[1;32m    316\u001b[0m                 \u001b[0mbatch_prompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mpipeline_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/text_generation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m                         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m     def preprocess(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1358\u001b[0m                     \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1359\u001b[0m                 )\n\u001b[0;32m-> 1360\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/pt_utils.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# We're out of items within a batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0mprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;31m# We now have a batch of \"inferred things\".\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/pt_utils.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# We're out of items within a batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0mprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0;31m# We now have a batch of \"inferred things\".\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader_batch_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1284\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0minference_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m                     \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1286\u001b[0;31m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1287\u001b[0m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/text_generation.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0mgenerate_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"generation_config\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneration_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mgenerate_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModelOutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, **kwargs)\u001b[0m\n\u001b[1;32m   2463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2464\u001b[0m             \u001b[0;31m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2465\u001b[0;31m             result = self._sample(\n\u001b[0m\u001b[1;32m   2466\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2467\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepared_logits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3432\u001b[0m                 \u001b[0mis_prefill\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3433\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3434\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3436\u001b[0m             \u001b[0;31m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    966\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_requested_to_return_tuple\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mis_configured_to_return_tuple\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_top_level_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/deprecation.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/gemma2/modeling_gemma2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, cache_position, logits_to_keep, **loss_kwargs)\u001b[0m\n\u001b[1;32m    849\u001b[0m         )\n\u001b[1;32m    850\u001b[0m         \u001b[0;31m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 851\u001b[0;31m         outputs: BaseModelOutputWithPast = self.model(\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    966\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_requested_to_return_tuple\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mis_configured_to_return_tuple\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_top_level_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/gemma2/modeling_gemma2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, cache_position, last_cache_position, **flash_attn_kwargs)\u001b[0m\n\u001b[1;32m    632\u001b[0m                 )\n\u001b[1;32m    633\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m                 layer_outputs = decoder_layer(\n\u001b[0m\u001b[1;32m    635\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m                     \u001b[0mposition_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_embeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/gemma2/modeling_gemma2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, position_embeddings, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, last_cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre_feedforward_layernorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_feedforward_layernorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/gemma2/modeling_gemma2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mdown_proj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgate_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdown_proj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}